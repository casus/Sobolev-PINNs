{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, './PSM_V1')\n",
    "from sobolev import Sobolev\n",
    "from solver import Solver\n",
    "from utils import matmul\n",
    "from diffeomorphisms import hyper_rect\n",
    "import surrogates\n",
    "import matplotlib.pyplot as plt\n",
    "from pinnutils import PINN\n",
    "#from pinnutils import PINNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "# a=-1.0, b=1.0, q=3, sob_2d(deg=30), sob_1d(deg=100), model(n=30, p=np.inf), s=[0,-1], optimizer:LBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Quantum Harmonic Oscillator\n",
    "$$\n",
    "\\biggr\\{\\begin{array}{rll}\n",
    "       -\\Delta u(x) + V(u(x))  &= \\lambda u(x)  &,  \\forall x\\in\\Omega  \\\\\n",
    "         u(x)  -g(x)     &= 0   &,  \\forall x\\in\\partial\\Omega\n",
    "\\end{array}\n",
    "$$\n",
    "with, \n",
    "$$g(x_1,x_2) = \\frac{\\pi^{-1/4}}{ \\sqrt{2^{n_1+n_2}n_1!n_2!}}e^{-\\frac{(x_1^2+x_2^2)}{2}}H_{n_1}(x_1)H_{n_2}(x_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doamin 0ounds\n",
    "lb = np.array([-1, -1.0, 0.0])\n",
    "ub = np.array([1.0, 1.0, 0])\n",
    "n_x = 15\n",
    "n_y = 15\n",
    "omega = n_x + n_y +1\n",
    "#Create 2-D Dataset from the analytical solution\n",
    "def Herm_pol(n):\n",
    "    #p =  sp.Symbol('p')\n",
    "    #Hn = sp.lambdify(p,sp.hermite(n, p))\n",
    "    return scipy.special.hermite(n)\n",
    "#lam = int(eigenvalue(e_l,e_l)(0,0))\n",
    "def Psi (x,y,n_x, n_y):\n",
    "    Hnx= Herm_pol(n_x)\n",
    "    Hny= Herm_pol(n_y)\n",
    "    #psi_t = torch.exp(torch.complex(torch.Tensor([0]),torch.Tensor([0])))\n",
    "    return 1/((2**(n_x+n_y)*scipy.math.factorial(n_y)*scipy.math.factorial(n_x))**(1/2))*(np.pi**(-1/4))*np.exp(-(x**2+y**2)/2)*Hnx(x)*Hny(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# Sobolev Cubature\n",
    "diffeo_2d = hyper_rect(*rect)\n",
    "diffeo_1d_0 = hyper_rect(rect[0])\n",
    "diffeo_1d_1 = hyper_rect(rect[1])\n",
    "\n",
    "sob_2d = Sobolev(deg=30, dim=2, diffeo=diffeo_2d)\n",
    "sob_1d_0 = Sobolev(deg=100, diffeo=diffeo_1d_0)\n",
    "sob_1d_1 = Sobolev(deg=100, diffeo=diffeo_1d_1)\n",
    "\n",
    "dx2, dy2 = torch.tensor(sob_2d.diff.diffs(np.array([[2,0],[0,2]])), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |--------------------------------------------|\n",
    "# |  Operator  |          Formulation          |  \n",
    "# |------------|-------------------------------|\n",
    "# | id         |  L2 grad of L2                | \n",
    "# | m_inv      |  L2 grad of Sob               |\n",
    "# | weak m_inv |  L2 grad of weak Sob          |\n",
    "# | m          |  L2 grad of negative Sob      |\n",
    "# | weak m     |  L2 grad of weak negative Sob |\n",
    "# |--------------------------------------------|\n",
    "#\n",
    "# For that use:\n",
    "# -> sob.set_s(s)\n",
    "# -> sob.metric(rev=False/True, weak=False/True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobolev Order\n",
    "sob_2d.set_s(-1)\n",
    "sob_1d_0.set_s(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160119/1546417973.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_d = torch.tensor(X_t.reshape(-1), dtype = torch.float32)\n",
      "/tmp/ipykernel_160119/1546417973.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_d = torch.tensor(Y_t.reshape(-1), dtype = torch.float32)\n",
      "/tmp/ipykernel_160119/1546417973.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_pde = torch.tensor(torch.cat((X_t.reshape(-1,1), Y_t.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
      "/tmp/ipykernel_160119/1546417973.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_bdl = torch.tensor(torch.cat((xs_bdx.reshape(-1,1), rect[1][0]*torch.ones(len(xs_bdx)).reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
      "/tmp/ipykernel_160119/1546417973.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_bdr = torch.tensor(torch.cat((xs_bdx.reshape(-1,1), rect[1][1]*torch.ones(len(xs_bdx)).reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
      "/tmp/ipykernel_160119/1546417973.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_bdl = torch.tensor(torch.cat((rect[0][0]*torch.ones(len(xs_bdx)).reshape(-1,1),xs_bdx.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
      "/tmp/ipykernel_160119/1546417973.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_bdr = torch.tensor(torch.cat((rect[0][1]*torch.ones(len(xs_bdx)).reshape(-1,1),xs_bdx.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
      "/tmp/ipykernel_160119/1546417973.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  w_2d = torch.tensor(sob_2d.get_leja_weights(), dtype = torch.float32)\n",
      "/tmp/ipykernel_160119/1546417973.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  w_1d = torch.tensor(sob_1d_0.get_leja_weights(), dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "_, xs_bndr_0 = sob_1d_0.get_xs()\n",
    "_, xs_bndr_1 = sob_1d_1.get_xs()\n",
    "xs_plt, xs = sob_2d.get_xs()\n",
    "leja_grid_2d = sob_2d.get_leja_grid()\n",
    "xs = torch.tensor(xs)\n",
    "xs_bdx =  torch.tensor(xs_bndr_0[0])\n",
    "X_t, Y_t = torch.meshgrid(xs[0],xs[1])\n",
    "X_d = torch.tensor(X_t.reshape(-1), dtype = torch.float32)\n",
    "Y_d = torch.tensor(Y_t.reshape(-1), dtype = torch.float32)\n",
    "X_pde = torch.tensor(torch.cat((X_t.reshape(-1,1), Y_t.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
    "X_bdl = torch.tensor(torch.cat((xs_bdx.reshape(-1,1), rect[1][0]*torch.ones(len(xs_bdx)).reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
    "X_bdr = torch.tensor(torch.cat((xs_bdx.reshape(-1,1), rect[1][1]*torch.ones(len(xs_bdx)).reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
    "Y_bdl = torch.tensor(torch.cat((rect[0][0]*torch.ones(len(xs_bdx)).reshape(-1,1),xs_bdx.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
    "Y_bdr = torch.tensor(torch.cat((rect[0][1]*torch.ones(len(xs_bdx)).reshape(-1,1),xs_bdx.reshape(-1,1)),1), dtype = torch.float32, requires_grad = True)\n",
    "u_bdxl = torch.tensor(Psi(xs_bndr_0[0], rect[1][0].reshape(-1),n_x,n_y), dtype = torch.float32)\n",
    "u_bdxr = torch.tensor(Psi(xs_bndr_0[0], rect[1][1].reshape(-1),n_x,n_y), dtype = torch.float32)\n",
    "u_bdyl= torch.tensor(Psi(rect[0][0].reshape(-1,1), xs_bndr_1[0],n_x,n_y).reshape(-1), dtype = torch.float32)\n",
    "u_bdyr= torch.tensor(Psi(rect[0][1].reshape(-1,1), xs_bndr_1[0],n_x,n_y).reshape(-1), dtype = torch.float32)\n",
    "w_2d = torch.tensor(sob_2d.get_leja_weights(), dtype = torch.float32)\n",
    "w_1d = torch.tensor(sob_1d_0.get_leja_weights(), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sobolev Metrics\n",
    "metric_2d = sob_2d.metric()#(weak=True)\n",
    "metric_1d_0 = sob_1d_0.l2_metric()\n",
    "metric_1d_1 = sob_1d_1.l2_metric()\n",
    "\n",
    "# Formulation\n",
    "K_x = 1/2*(dx2+dy2)\n",
    "V = 1/2*torch.diag((X_d**2 + Y_d**2))\n",
    "eq = lambda u: -matmul(K_x, u)+ matmul(V,u)- (n_x+n_y+1)*u\n",
    "crit_pde = lambda u: sob_2d.loss(eq(u), weak=True)\n",
    "crit_bdxl = lambda u: sob_1d_0.l2_loss(u-u_bdxl)\n",
    "crit_bdxr = lambda u: sob_1d_0.l2_loss(u-u_bdxr)\n",
    "crit_bdyl = lambda u: sob_1d_0.l2_loss(u-u_bdyl)\n",
    "crit_bdyr = lambda u: sob_1d_0.l2_loss(u-u_bdyr)\n",
    "#grad_dmn = lambda u: 2*matmul(K.T, metric_2d(eq(u)))\n",
    "#grad_bndr_0 = lambda u: 2*metric_1d_0(u-u_bndr_0)\n",
    "#grad_bndr_1 = lambda u: 2*metric_1d_1(u-u_bndr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160119/3477663626.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.mean(abs(eq(torch.tensor(Psi(X_d,Y_d,n_x,n_x), dtype = torch.float32))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.4260e-05)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(abs(eq(torch.tensor(Psi(X_d,Y_d,n_x,n_x), dtype = torch.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = np.concatenate([X_pde.detach().numpy(),X_bdl.detach().numpy(), X_bdr.detach().numpy(), Y_bdl.detach().numpy() , Y_bdl.detach().numpy()], 0)\n",
    "# compute mean and std of training data\n",
    "X_mean = torch.tensor(np.mean(TD, axis=0, keepdims=True),device=device)\n",
    "X_std = torch.tensor(np.std(TD, axis=0, keepdims=True),device=device)\n",
    "seedc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from itertools import product, combinations\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR, MultiStepLR\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "class sine(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return torch.sin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optim):\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_s = torch.max(torch.linalg.eig(dy2)[0].real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#parameters: 7851\n",
      "epoch 17826/30000, loss=0.0000883300, lambda=1.0000, lr=0.00010\t\t\t\r"
     ]
    }
   ],
   "source": [
    "net = PINN(sizes=[2,50,50,50,50,1], mean=X_mean, std=X_std, seed=seedc, activation=sine()).to(device)\n",
    "print(\"#parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
    "n_epochs   = 30000\n",
    "lamb  = 1\n",
    "losses_bc  = [];\n",
    "losses_reg = [];\n",
    "params = [{'params': net.parameters()}]\n",
    "milestones = [[15000,25000]]\n",
    "optimizer = torch.optim.Adam(params)\n",
    "scheduler = MultiStepLR(optimizer, milestones[0], gamma=0.1)\n",
    "start_time = time.time()\n",
    "ds = 1\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    uhat  = net(X_pde).T[0]\n",
    "    #l_pde   = crit_pde(uhat)\n",
    "    l_pde = torch.sum((eq(uhat)**2*w_2d))\n",
    "    predxl = net(X_bdl).T[0]\n",
    "    predxr = net(X_bdr).T[0]\n",
    "    predyl = net(Y_bdl).T[0]\n",
    "    predyr = net(Y_bdr).T[0]\n",
    "    #l_bc = crit_bdxl(predxl) + crit_bdxr(predxr) + crit_bdyl(predyl) + crit_bdyr(predyr) \n",
    "    l_bc = torch.sum(((predxl-u_bdxl)**2*w_1d))+torch.sum(((predxr-u_bdxr)**2*w_1d))+torch.sum(((predyl-u_bdyl)**2*w_1d))\n",
    "    l_bc += torch.sum(((predyr-u_bdyr)**2*w_1d))\n",
    "    \n",
    "    loss = l_pde/100 + l_bc\n",
    "    losses_bc.append(l_bc.item())\n",
    "    losses_reg.append(l_pde.item())\n",
    "    \n",
    "    #loss.backward()\n",
    "    optimizer.step(\n",
    "                lambda: closure(\n",
    "                    optimizer,\n",
    "                ))\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"epoch {}/{}, loss={:.10f}, lambda={:.4f}, lr={:,.5f}\\t\\t\\t\"\n",
    "          .format(epoch+1, n_epochs, loss.item(), lamb, optimizer.param_groups[0]['lr']), end=\"\\r\")\n",
    "        \n",
    "elapsed_time = time.time() - start_time\n",
    "print('CPU time = ',elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = torch.meshgrid(torch.linspace(-1,1,100),torch.linspace(-1,1,100))\n",
    "X_T = torch.cat((X_test.reshape(-1,1), Y_test.reshape(-1,1)),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 25), dpi=80)\n",
    "u_sol = Psi(X_test,Y_test,n_x,n_y).detach().numpy()\n",
    "out = net(X_T).reshape(100,100).detach().numpy()\n",
    "#out = N_p()._eval(X_r).reshape(100,100)\n",
    "L0_inf = np.max(abs(out.reshape(-1)-u_sol.reshape(-1)))\n",
    "#Lp_inf = torch.max(abs(poisson_residual(net_s(inp_r),inp_r,omega).reshape(-1)))\n",
    "L0_mean =np.mean(abs(out.reshape(-1)-u_sol.reshape(-1)))\n",
    "print(\"pred rel. linf-error = {:e}\".format(L0_inf))\n",
    "print(\"pred rel. l2-error = {:e}\".format(L0_mean))\n",
    "#print(\"pde res. linf-error = {:e}\".format(Lp_inf))\n",
    "print(\"pred_rel_std. linf-error = {:e}\".format(np.std(abs(out.reshape(-1)-u_sol.reshape(-1)))))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(u_sol, cmap=\"Spectral\", origin=\"lower\")\n",
    "#plt.xticks(np.arange(0,len(x)+1,25), np.arange(0, 1.1, 0.25))\n",
    "#plt.yticks(np.arange(0,len(y)+1,25), np.arange(0, 1.1, 0.25))\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.title(\"Ground Truth\")\n",
    "#plt.clim(-1,1)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(out, cmap=\"Spectral\", origin=\"lower\")\n",
    "#plt.xticks(np.linspace(0,len(x)+1,5),np.linspace(-1, 1, 5))\n",
    "#plt.yticks(np.linspace(0,len(x)+1,5),np.linspace(-1, 1, 5))\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.title(\"Prediction\")\n",
    "#plt.clim(-1,1)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(np.abs(out-u_sol), cmap=\"Spectral\", origin=\"lower\")\n",
    "#plt.xticks(np.linspace(0,len(x)+1,5),np.linspace(-1, 1, 5))\n",
    "#plt.yticks(np.linspace(0,len(x)+1,5),np.linspace(-1, 1, 5))\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.title(\"Point-wise Error\")\n",
    "plt.clim(0,0.2)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "#plt.gcf().set_size_inches(14,4)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(folder + 'pred_error_MSE.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
